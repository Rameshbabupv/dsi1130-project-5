{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Group Project\n",
    "#### Author: Adam Pardo, Brandon Bergeron, Eric Bayless, Ramesh Babu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 - ML modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Comparing different Maching Learning models on our sample data containing ~400 restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--formatted printing for model scores\n",
    "\n",
    "def print_scores(model):\n",
    "    print(f'train score: {model.score(x_train, y_train)}')\n",
    "    print(f'test score: {model.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#--- Getting feature importances- only for pipelines\n",
    "def get_imports(pipe, transformer, estimator, imports):\n",
    "    '''\n",
    "    takes a pipeline, it's named transformer, it's named estimator, and # of important features desired\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        pipe: name of pipeline instance\n",
    "        transformer (str): ex 'countvectorizer'\n",
    "        estimator (str): ex. 'logisticregression', 'ridge'\n",
    "        imports (int): number of important features desired\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    features = pipe.named_steps[transformer].get_feature_names()\n",
    "    coefs = pipe.named_steps[estimator].coef_\n",
    "    coefs_df = pd.DataFrame({'importance': coefs[0]}, index = features)\n",
    "    \n",
    "    return coefs_df.sort_values('importance', ascending=False).head(imports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in reviews and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines all reviews for each restaurant into one observation\n",
    "\n",
    "#-read in reviews\n",
    "#df_reviews = pd.read_csv('../data/Las_Vegas_400_reviews.csv')\n",
    "df_reviews = pd.read_csv('../data/Las_Vegas_reviews.csv')\n",
    "\n",
    "#--combine all reviews\n",
    "df_revs_combined = df_reviews.groupby(['business_id', 'name', \n",
    "                               'address', 'city' ,\n",
    "                               'state', 'postal_code', \n",
    "                               'latitude' ,'longitude' , \n",
    "                               'stars', 'review_count', \n",
    "                               'is_open', 'attributes', 'categories']).agg({'text': ' '.join})\n",
    "\n",
    "#--reset index and add review length column for total \n",
    "df_revs_combined = df_revs_combined.reset_index()\n",
    "df_revs_combined['review_wc'] = df_revs_combined['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>review_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0RkJ_uIduNLWQrphbADRw</td>\n",
       "      <td>Rooster Boy Cafe</td>\n",
       "      <td>2620 Regatta Dr, Ste 113</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89128</td>\n",
       "      <td>36.207539</td>\n",
       "      <td>-115.268154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WheelchairAccessible': 'True', 'RestaurantsP...</td>\n",
       "      <td>Coffee &amp; Tea, Restaurants, Cafes, Food, Breakf...</td>\n",
       "      <td>Amazing food and service. So grateful for the ...</td>\n",
       "      <td>24200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id              name                   address  \\\n",
       "0  -0RkJ_uIduNLWQrphbADRw  Rooster Boy Cafe  2620 Regatta Dr, Ste 113   \n",
       "\n",
       "        city state  postal_code   latitude   longitude  stars  review_count  \\\n",
       "0  Las Vegas    NV        89128  36.207539 -115.268154    4.0           194   \n",
       "\n",
       "   is_open                                         attributes  \\\n",
       "0        1  {'WheelchairAccessible': 'True', 'RestaurantsP...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Coffee & Tea, Restaurants, Cafes, Food, Breakf...   \n",
       "\n",
       "                                                text  review_wc  \n",
       "0  Amazing food and service. So grateful for the ...      24200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: 72% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.724548\n",
       "0    0.275452\n",
       "Name: is_open, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined['is_open'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_revs_combined['text']\n",
    "y = df_revs_combined['is_open']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(stop_words='english', max_features=500)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "ss = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'LogisticRegression' : LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'RandomForest' : RandomForestClassifier(n_jobs=-1),\n",
    "    'ExtraTrees' : ExtraTreesClassifier(n_jobs=-1),\n",
    "    'K-NearestNeighbors' : KNeighborsClassifier(n_jobs=-1),\n",
    "    'SVC' : SVC(),\n",
    "    'AdaBoostClassifier' : AdaBoostClassifier(n_estimators=100),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with CountVectorizer:\n",
      "train score: 0.9260935143288085\n",
      "test score: 0.7760180995475113\n",
      "\n",
      "LogisticRegression with TfidfVectorizer:\n",
      "train score: 0.995475113122172\n",
      "test score: 0.7579185520361991\n",
      "\n",
      "\n",
      "\n",
      "MultinomialNB with CountVectorizer:\n",
      "train score: 0.7187028657616893\n",
      "test score: 0.6628959276018099\n",
      "\n",
      "MultinomialNB with TfidfVectorizer:\n",
      "train score: 0.702865761689291\n",
      "test score: 0.6470588235294118\n",
      "\n",
      "\n",
      "\n",
      "RandomForest with CountVectorizer:\n",
      "train score: 0.27526395173454\n",
      "test score: 0.27601809954751133\n",
      "\n",
      "RandomForest with TfidfVectorizer:\n",
      "train score: 1.0\n",
      "test score: 0.7873303167420814\n",
      "\n",
      "\n",
      "\n",
      "ExtraTrees with CountVectorizer:\n",
      "train score: 0.30844645550527905\n",
      "test score: 0.3009049773755656\n",
      "\n",
      "ExtraTrees with TfidfVectorizer:\n",
      "train score: 1.0\n",
      "test score: 0.7782805429864253\n",
      "\n",
      "\n",
      "\n",
      "K-NearestNeighbors with CountVectorizer:\n",
      "train score: 0.7285067873303167\n",
      "test score: 0.7330316742081447\n",
      "\n",
      "K-NearestNeighbors with TfidfVectorizer:\n",
      "train score: 0.8092006033182504\n",
      "test score: 0.7239819004524887\n",
      "\n",
      "\n",
      "\n",
      "SVC with CountVectorizer:\n",
      "train score: 0.72473604826546\n",
      "test score: 0.7239819004524887\n",
      "\n",
      "SVC with TfidfVectorizer:\n",
      "train score: 0.9042232277526395\n",
      "test score: 0.7895927601809954\n",
      "\n",
      "\n",
      "\n",
      "AdaBoostClassifier with CountVectorizer:\n",
      "train score: 0.722473604826546\n",
      "test score: 0.7262443438914027\n",
      "\n",
      "AdaBoostClassifier with TfidfVectorizer:\n",
      "train score: 0.9705882352941176\n",
      "test score: 0.8122171945701357\n",
      "\n",
      "\n",
      "\n",
      "GradientBoostingClassifier with CountVectorizer:\n",
      "train score: 0.27526395173454\n",
      "test score: 0.27601809954751133\n",
      "\n",
      "GradientBoostingClassifier with TfidfVectorizer:\n",
      "train score: 0.9917043740573153\n",
      "test score: 0.8099547511312217\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_models = {}\n",
    "\n",
    "for key in model_dict.keys():  \n",
    "    \n",
    "    estimator = model_dict[key]\n",
    "\n",
    "    pipe_cvect = make_pipeline(cvect, ss, estimator)\n",
    "    pipe_tfidf = make_pipeline(tfidf, ss, estimator)\n",
    "\n",
    "    pipe_cvect.fit(x_train, y_train)\n",
    "    pipe_tfidf.fit(x_train, y_train)\n",
    "    \n",
    "    df_models[f'{key}_1'] = {\n",
    "        'preprocessing' : 'CountVectorizer',\n",
    "        'train_score' : pipe_cvect.score(x_train, y_train),\n",
    "        'test_score' : pipe_cvect.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    df_models[f'{key}_2'] = {\n",
    "        'preprocessing' : 'TfidfVectorizer',\n",
    "        'train_score' : pipe_tfidf.score(x_train, y_train),\n",
    "        'test_score' : pipe_tfidf.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'{key} with CountVectorizer:')\n",
    "    print_scores(pipe_cvect)\n",
    "    print()\n",
    "    print(f'{key} with TfidfVectorizer:')\n",
    "    print_scores(pipe_tfidf)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.926094</td>\n",
       "      <td>0.776018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.995475</td>\n",
       "      <td>0.757919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.662896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.275264</td>\n",
       "      <td>0.276018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.308446</td>\n",
       "      <td>0.300905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-NearestNeighbors_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.733032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-NearestNeighbors_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.723982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.723982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.904223</td>\n",
       "      <td>0.789593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.726244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.812217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.275264</td>\n",
       "      <td>0.276018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.991704</td>\n",
       "      <td>0.809955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocessing train_score test_score\n",
       "LogisticRegression_1          CountVectorizer    0.926094   0.776018\n",
       "LogisticRegression_2          TfidfVectorizer    0.995475   0.757919\n",
       "MultinomialNB_1               CountVectorizer    0.718703   0.662896\n",
       "MultinomialNB_2               TfidfVectorizer    0.702866   0.647059\n",
       "RandomForest_1                CountVectorizer    0.275264   0.276018\n",
       "RandomForest_2                TfidfVectorizer           1    0.78733\n",
       "ExtraTrees_1                  CountVectorizer    0.308446   0.300905\n",
       "ExtraTrees_2                  TfidfVectorizer           1   0.778281\n",
       "K-NearestNeighbors_1          CountVectorizer    0.728507   0.733032\n",
       "K-NearestNeighbors_2          TfidfVectorizer    0.809201   0.723982\n",
       "SVC_1                         CountVectorizer    0.724736   0.723982\n",
       "SVC_2                         TfidfVectorizer    0.904223   0.789593\n",
       "AdaBoostClassifier_1          CountVectorizer    0.722474   0.726244\n",
       "AdaBoostClassifier_2          TfidfVectorizer    0.970588   0.812217\n",
       "GradientBoostingClassifier_1  CountVectorizer    0.275264   0.276018\n",
       "GradientBoostingClassifier_2  TfidfVectorizer    0.991704   0.809955"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_models = pd.DataFrame(df_models).T\n",
    "df_first_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/first_models.data', 'wb') as fh:\n",
    "#    pickle.dump(df_first_models, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tokenizer and Parameter Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lemmatize(text):\n",
    "    'returns a lowercase lemmatized list of words'\n",
    "    text_lower = text.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(x) for x in text_lower.split()])\n",
    "\n",
    "tfidf_lem = TfidfVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=750)\n",
    "cvect_lem = CountVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = tfidf_lem.fit_transform(x_train)\n",
    "x_test_tf = tfidf_lem.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cv = cvect_lem.fit_transform(x_train)\n",
    "x_test_cv = cvect_lem.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.7624434389140271\n",
      "best params: {'logisticregression__C': 0, 'logisticregression__penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "pipe_logreg = make_pipeline(ss, logreg)\n",
    "\n",
    "params = {\n",
    "    'logisticregression__C' : [0, 1, 10, 100],\n",
    "    'logisticregression__penalty' : ['l1', 'l2', 'elasticnet', 'none'],    \n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(pipe_logreg, params, n_jobs=-1)\n",
    "grid_logreg.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('Logistic Regression with GridSearch')\n",
    "print(f'train score: {grid_logreg.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_logreg.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_logreg.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.9992458521870287\n",
      "test score: 0.7828054298642534\n",
      "best params: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_forest = make_pipeline(ss, forest)\n",
    "\n",
    "params_forest = {\n",
    "    'randomforestclassifier__min_samples_leaf' : [3, 5, 10, 20],\n",
    "    'randomforestclassifier__n_estimators' : [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth' : [5, 10, 20, None]\n",
    "}\n",
    "\n",
    "grid_forest = GridSearchCV(pipe_forest, params_forest, n_jobs=-1)\n",
    "\n",
    "grid_forest.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_forest.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_forest.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_forest.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.7835595776772247\n",
      "test score: 0.751131221719457\n",
      "best params: {'kneighborsclassifier__n_neighbors': 15, 'kneighborsclassifier__p': 1}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_knn = make_pipeline(ss, knn)\n",
    "\n",
    "params_knn = {\n",
    "    'kneighborsclassifier__n_neighbors' : [3, 5, 7, 9, 15],\n",
    "    'kneighborsclassifier__p' : [1, 2]\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(pipe_knn, params_knn, n_jobs=-1)\n",
    "\n",
    "grid_knn.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_knn.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_knn.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_knn.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with GridSearch:\n",
      "train score: 0.9992458521870287\n",
      "test score: 0.8212669683257918\n",
      "best params: {'svc__C': 5, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "pipe_svc = make_pipeline(ss, svc)\n",
    "\n",
    "params_svc = {\n",
    "    'svc__kernel' : ['rbf', 'sigmoid'],\n",
    "    'svc__C' : [0, 1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, params_svc, n_jobs=-1)\n",
    "grid_svc.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('SVC with GridSearch:')\n",
    "print(f'train score: {grid_svc.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_svc.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.7873303167420814\n",
      "best_params: {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "pipe_boost = make_pipeline(ss, adaboost)\n",
    "\n",
    "params_boost = {\n",
    "    'adaboostclassifier__n_estimators' : [50, 100, 200],\n",
    "    'adaboostclassifier__learning_rate' : [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_boost = GridSearchCV(pipe_boost, params_boost, n_jobs=-1)\n",
    "grid_boost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('AdaBoost with GridSearch')\n",
    "print(f'train score: {grid_boost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_boost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_boost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoost with GridSearch\n",
      "train score: 0.72473604826546\n",
      "test score: 0.7239819004524887\n",
      "best_params: {'gradientboostingclassifier__ccp_alpha': 1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "pipe_gboost = make_pipeline(ss, gboost)\n",
    "\n",
    "params_gboost = {\n",
    "    'gradientboostingclassifier__min_samples_leaf' : [3, 6, 10, 20],\n",
    "    'gradientboostingclassifier__max_depth' : [3, 5, 9],\n",
    "    'gradientboostingclassifier__ccp_alpha' : [1, 10, 100]\n",
    "\n",
    "}\n",
    "\n",
    "grid_gboost = GridSearchCV(pipe_gboost, params_gboost, n_jobs=-1)\n",
    "grid_gboost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('GradBoost with GridSearch')\n",
    "print(f'train score: {grid_gboost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_gboost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_gboost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing GridSearch Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Dictionary of all GridSearches for bilding DF of metrics\n",
    "\n",
    "grid_dict = {\n",
    "    'LogisticRegression' : {'preprocesser':'cv', 'model':grid_logreg},\n",
    "    'RandomForest' : {'preprocesser':'tf', 'model':grid_forest},\n",
    "    'KNN' : {'preprocesser':'cv', 'model':grid_knn},\n",
    "    'SVC' : {'preprocesser':'tf', 'model':grid_svc},\n",
    "    'AdaBoostClassifier' : {'preprocesser':'tf', 'model':grid_boost},\n",
    "    'GradientBoostingClassifier' : {'preprocesser':'tf', 'model':grid_gboost}\n",
    "}\n",
    "\n",
    "metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(with_mean=False),\n",
       " 'logisticregression': LogisticRegression(C=0, max_iter=1000, n_jobs=-1, penalty='none')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logreg.best_estimator_.named_steps['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Builds DF of metrics for all GridSearches\n",
    "\n",
    "for grid in grid_dict.keys():\n",
    "    if grid_dict[grid]['preprocesser'] == 'cv':\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_cv)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_cv, y_test)\n",
    "        }\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_tf)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_tf, y_test)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.850163</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.719288</td>\n",
       "      <td>0.762443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.778607</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.270492</td>\n",
       "      <td>0.624308</td>\n",
       "      <td>0.782805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.584682</td>\n",
       "      <td>0.751131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.565574</td>\n",
       "      <td>0.742162</td>\n",
       "      <td>0.821267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.727536</td>\n",
       "      <td>0.825792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.723982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.723982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            precision    recall  specificity  \\\n",
       "LogisticRegression           0.850163  0.815625     0.622951   \n",
       "RandomForest                 0.778607  0.978125     0.270492   \n",
       "KNN                          0.761194  0.956250     0.213115   \n",
       "SVC                          0.847262  0.918750     0.565574   \n",
       "AdaBoostClassifier           0.834711  0.946875     0.508197   \n",
       "GradientBoostingClassifier   0.723982  1.000000     0.000000   \n",
       "\n",
       "                            balanced accuracy  accuracy  \n",
       "LogisticRegression                   0.719288  0.762443  \n",
       "RandomForest                         0.624308  0.782805  \n",
       "KNN                                  0.584682  0.751131  \n",
       "SVC                                  0.742162  0.821267  \n",
       "AdaBoostClassifier                   0.727536  0.825792  \n",
       "GradientBoostingClassifier           0.500000  0.723982  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--DF of all metrics for best models\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_dict).T\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/gridsearch_metrics.data', 'wb') as fh:\n",
    "#    pickle.dump(df_metrics, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
