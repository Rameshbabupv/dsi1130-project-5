{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Group Project\n",
    "#### Author: Adam Pardo, Brandon Bergeron, Eric Bayless, Ramesh Babu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 - ML modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Comparing different Maching Learning models on our sample data containing ~400 restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--formatted printing for model scores\n",
    "\n",
    "def print_scores(model):\n",
    "    print(f'train score: {model.score(x_train, y_train)}')\n",
    "    print(f'test score: {model.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in reviews and combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines all reviews for each restaurant into one observation\n",
    "\n",
    "#-read in reviews\n",
    "\n",
    "df_reviews = pd.read_csv('../data/Las_Vegas_reviews.csv') #-- All reviews\n",
    "#df_reviews = pd.read_csv('../data/Las_Vegas_400_reviews.csv') #-- Initial Sample\n",
    "\n",
    "\n",
    "#--combine all reviews\n",
    "df_revs_combined = df_reviews.groupby(['business_id', 'name', \n",
    "                               'address', 'city' ,\n",
    "                               'state', 'postal_code', \n",
    "                               'latitude' ,'longitude' , \n",
    "                               'stars', 'review_count', \n",
    "                               'is_open', 'attributes', 'categories']).agg({'text': ' '.join})\n",
    "\n",
    "#--reset index and add review length column for total \n",
    "df_revs_combined = df_revs_combined.reset_index()\n",
    "df_revs_combined['review_wc'] = df_revs_combined['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>review_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0RkJ_uIduNLWQrphbADRw</td>\n",
       "      <td>Rooster Boy Cafe</td>\n",
       "      <td>2620 Regatta Dr, Ste 113</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89128</td>\n",
       "      <td>36.207539</td>\n",
       "      <td>-115.268154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WheelchairAccessible': 'True', 'RestaurantsP...</td>\n",
       "      <td>Coffee &amp; Tea, Restaurants, Cafes, Food, Breakf...</td>\n",
       "      <td>Amazing food and service. So grateful for the ...</td>\n",
       "      <td>24200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id              name                   address  \\\n",
       "0  -0RkJ_uIduNLWQrphbADRw  Rooster Boy Cafe  2620 Regatta Dr, Ste 113   \n",
       "\n",
       "        city state  postal_code   latitude   longitude  stars  review_count  \\\n",
       "0  Las Vegas    NV        89128  36.207539 -115.268154    4.0           194   \n",
       "\n",
       "   is_open                                         attributes  \\\n",
       "0        1  {'WheelchairAccessible': 'True', 'RestaurantsP...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Coffee & Tea, Restaurants, Cafes, Food, Breakf...   \n",
       "\n",
       "                                                text  review_wc  \n",
       "0  Amazing food and service. So grateful for the ...      24200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: 72% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.724548\n",
       "0    0.275452\n",
       "Name: is_open, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_revs_combined['is_open'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TTS, stratifying for imbalanced y\n",
    "\n",
    "x = df_revs_combined['text']\n",
    "y = df_revs_combined['is_open']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Preprocessors used in all models\n",
    "cvect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "ss = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.7895927601809954\n"
     ]
    }
   ],
   "source": [
    "#-- Basic Logistic Regression to guage performance and get some feature imports for EDA\n",
    "\n",
    "logr = LogisticRegression(n_jobs=-1, max_iter=1000)\n",
    "\n",
    "pipe_logr = make_pipeline(cvect, ss, logr)\n",
    "pipe_logr.fit(x_train, y_train)\n",
    "\n",
    "print_scores(pipe_logr)\n",
    "\n",
    "#-- Extracting features and imports\n",
    "features = pipe_logr.named_steps.countvectorizer.get_feature_names()\n",
    "coefs = pipe_logr.named_steps.logisticregression.coef_\n",
    "coefs_df = pd.DataFrame({'importance': coefs[0]}, index = features)\n",
    "\n",
    "neg_imports = coefs_df.sort_values('importance', ascending=False).tail(50)\n",
    "pos_imports = coefs_df.sort_values('importance', ascending=False).head(50)\n",
    "\n",
    "#-- Combine imports into one df\n",
    "pos_neg_imports = pd.concat([pos_imports, neg_imports])\n",
    "\n",
    "#with open('pos_neg_imports.data', 'wb') as fh:\n",
    "    #pickle.dump(pos_neg_imports, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- instantiate basic versions of models to loop over\n",
    "\n",
    "model_dict = {\n",
    "    'LogisticRegression' : LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'RandomForest' : RandomForestClassifier(n_jobs=-1),\n",
    "    'ExtraTrees' : ExtraTreesClassifier(n_jobs=-1),\n",
    "    'K-NearestNeighbors' : KNeighborsClassifier(n_jobs=-1),\n",
    "    'SVC' : SVC(),\n",
    "    'AdaBoostClassifier' : AdaBoostClassifier(n_estimators=100),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Loop over base models with both vectorizers and get train/test scores for each\n",
    "\n",
    "df_models = {}\n",
    "\n",
    "for key in model_dict.keys():  \n",
    "    \n",
    "    estimator = model_dict[key]\n",
    "    \n",
    "    #-- pipelines for both vectorizers\n",
    "    pipe_cvect = make_pipeline(cvect, ss, estimator)\n",
    "    pipe_tfidf = make_pipeline(tfidf, ss, estimator)\n",
    "\n",
    "    #-- fit both \n",
    "    pipe_cvect.fit(x_train, y_train)\n",
    "    pipe_tfidf.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    #-- gets scores and adds to df_models\n",
    "    \n",
    "    df_models[f'{key}_1'] = {\n",
    "        'preprocessing' : 'CountVectorizer',\n",
    "        'train_score' : pipe_cvect.score(x_train, y_train),\n",
    "        'test_score' : pipe_cvect.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    df_models[f'{key}_2'] = {\n",
    "        'preprocessing' : 'TfidfVectorizer',\n",
    "        'train_score' : pipe_tfidf.score(x_train, y_train),\n",
    "        'test_score' : pipe_tfidf.score(x_test, y_test)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #--Printing for progress\n",
    "    #print(f'{key} with CountVectorizer:')\n",
    "    #print_scores(pipe_cvect)\n",
    "    #print()\n",
    "    #print(f'{key} with TfidfVectorizer:')\n",
    "    #print_scores(pipe_tfidf)\n",
    "    #print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.994721</td>\n",
       "      <td>0.780543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.651584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.644796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.319005</td>\n",
       "      <td>0.31448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.33635</td>\n",
       "      <td>0.309955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-NearestNeighbors_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.75641</td>\n",
       "      <td>0.723982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-NearestNeighbors_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.742081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.723982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.920814</td>\n",
       "      <td>0.79638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.726244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.981146</td>\n",
       "      <td>0.798643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.276772</td>\n",
       "      <td>0.276018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.996983</td>\n",
       "      <td>0.832579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocessing train_score test_score\n",
       "LogisticRegression_1          CountVectorizer    0.994721   0.780543\n",
       "LogisticRegression_2          TfidfVectorizer           1   0.773756\n",
       "MultinomialNB_1               CountVectorizer    0.728507   0.651584\n",
       "MultinomialNB_2               TfidfVectorizer    0.711161   0.644796\n",
       "RandomForest_1                CountVectorizer    0.319005    0.31448\n",
       "RandomForest_2                TfidfVectorizer           1   0.766968\n",
       "ExtraTrees_1                  CountVectorizer     0.33635   0.309955\n",
       "ExtraTrees_2                  TfidfVectorizer           1   0.764706\n",
       "K-NearestNeighbors_1          CountVectorizer     0.75641   0.723982\n",
       "K-NearestNeighbors_2          TfidfVectorizer    0.800905   0.742081\n",
       "SVC_1                         CountVectorizer    0.724736   0.723982\n",
       "SVC_2                         TfidfVectorizer    0.920814    0.79638\n",
       "AdaBoostClassifier_1          CountVectorizer    0.733032   0.726244\n",
       "AdaBoostClassifier_2          TfidfVectorizer    0.981146   0.798643\n",
       "GradientBoostingClassifier_1  CountVectorizer    0.276772   0.276018\n",
       "GradientBoostingClassifier_2  TfidfVectorizer    0.996983   0.832579"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_models = pd.DataFrame(df_models).T\n",
    "df_first_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/first_models.data', 'wb') as fh:\n",
    "#    pickle.dump(df_first_models, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tokenizer and Parameter Searching with GridSearchCV\n",
    "\n",
    "Each model will be fit using the word vectorizer that perfomed best on initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Tokenizer for \n",
    "\n",
    "def split_lemmatize(text):\n",
    "    'returns a lowercase lemmatized list of words'\n",
    "    text_lower = text.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(x) for x in text_lower.split()])\n",
    "\n",
    "tfidf_lem = TfidfVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=1000)\n",
    "cvect_lem = CountVectorizer(preprocessor = split_lemmatize, stop_words = 'english', max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Preprocessing words for model speed\n",
    "\n",
    "x_train_tf = tfidf_lem.fit_transform(x_train)\n",
    "x_test_tf = tfidf_lem.transform(x_test)\n",
    "\n",
    "x_train_cv = cvect_lem.fit_transform(x_train)\n",
    "x_test_cv = cvect_lem.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.7692307692307693\n",
      "best params: {'logisticregression__C': 0, 'logisticregression__penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "pipe_logreg = make_pipeline(ss, logreg)\n",
    "\n",
    "params = {\n",
    "    'logisticregression__C' : [0, 1, 10, 100],\n",
    "    'logisticregression__penalty' : ['l1', 'l2', 'elasticnet', 'none'],    \n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(pipe_logreg, params, n_jobs=-1)\n",
    "grid_logreg.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('Logistic Regression with GridSearch')\n",
    "print(f'train score: {grid_logreg.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_logreg.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_logreg.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.9984917043740573\n",
      "test score: 0.7647058823529411\n",
      "best params: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_forest = make_pipeline(ss, forest)\n",
    "\n",
    "params_forest = {\n",
    "    'randomforestclassifier__min_samples_leaf' : [3, 5, 10, 20],\n",
    "    'randomforestclassifier__n_estimators' : [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth' : [5, 10, 20, None]\n",
    "}\n",
    "\n",
    "grid_forest = GridSearchCV(pipe_forest, params_forest, n_jobs=-1)\n",
    "\n",
    "grid_forest.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_forest.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_forest.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_forest.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest with GridSearch:\n",
      "train score: 0.782051282051282\n",
      "test score: 0.7330316742081447\n",
      "best params: {'kneighborsclassifier__n_neighbors': 15, 'kneighborsclassifier__p': 1}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "pipe_knn = make_pipeline(ss, knn)\n",
    "\n",
    "params_knn = {\n",
    "    'kneighborsclassifier__n_neighbors' : [3, 5, 7, 9, 15],\n",
    "    'kneighborsclassifier__p' : [1, 2]\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(pipe_knn, params_knn, n_jobs=-1)\n",
    "\n",
    "grid_knn.fit(x_train_cv, y_train)\n",
    "\n",
    "\n",
    "print('RandomForest with GridSearch:')\n",
    "print(f'train score: {grid_knn.score(x_train_cv, y_train)}')\n",
    "print(f'test score: {grid_knn.score(x_test_cv, y_test)}')\n",
    "print(f'best params: {grid_knn.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with GridSearch:\n",
      "train score: 1.0\n",
      "test score: 0.8212669683257918\n",
      "best params: {'svc__C': 5, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "pipe_svc = make_pipeline(ss, svc)\n",
    "\n",
    "params_svc = {\n",
    "    'svc__kernel' : ['rbf', 'sigmoid'],\n",
    "    'svc__C' : [0, 1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, params_svc, n_jobs=-1)\n",
    "grid_svc.fit(x_train_tf, y_train)\n",
    "\n",
    "\n",
    "print('SVC with GridSearch:')\n",
    "print(f'train score: {grid_svc.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_svc.score(x_test_tf, y_test)}')\n",
    "print(f'best params: {grid_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with GridSearch\n",
      "train score: 1.0\n",
      "test score: 0.8009049773755657\n",
      "best_params: {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "pipe_boost = make_pipeline(ss, adaboost)\n",
    "\n",
    "params_boost = {\n",
    "    'adaboostclassifier__n_estimators' : [50, 100, 200],\n",
    "    'adaboostclassifier__learning_rate' : [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_boost = GridSearchCV(pipe_boost, params_boost, n_jobs=-1)\n",
    "grid_boost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('AdaBoost with GridSearch')\n",
    "print(f'train score: {grid_boost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_boost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_boost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoost with GridSearch\n",
      "train score: 0.72473604826546\n",
      "test score: 0.7239819004524887\n",
      "best_params: {'gradientboostingclassifier__ccp_alpha': 1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "pipe_gboost = make_pipeline(ss, gboost)\n",
    "\n",
    "params_gboost = {\n",
    "    'gradientboostingclassifier__min_samples_leaf' : [3, 6, 10, 20],\n",
    "    'gradientboostingclassifier__max_depth' : [3, 5, 9],\n",
    "    'gradientboostingclassifier__ccp_alpha' : [1, 10, 100]\n",
    "\n",
    "}\n",
    "\n",
    "grid_gboost = GridSearchCV(pipe_gboost, params_gboost, n_jobs=-1)\n",
    "grid_gboost.fit(x_train_tf, y_train)\n",
    "\n",
    "print('GradBoost with GridSearch')\n",
    "print(f'train score: {grid_gboost.score(x_train_tf, y_train)}')\n",
    "print(f'test score: {grid_gboost.score(x_test_tf, y_test)}')\n",
    "print(f'best_params: {grid_gboost.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing GridSearch Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Dictionary of all GridSearches for bilding DF of metrics\n",
    "\n",
    "grid_dict = {\n",
    "    'LogisticRegression' : {'preprocesser':'cv', 'model':grid_logreg},\n",
    "    'RandomForest' : {'preprocesser':'tf', 'model':grid_forest},\n",
    "    'KNN' : {'preprocesser':'cv', 'model':grid_knn},\n",
    "    'SVC' : {'preprocesser':'tf', 'model':grid_svc},\n",
    "    'AdaBoostClassifier' : {'preprocesser':'tf', 'model':grid_boost},\n",
    "    'GradientBoostingClassifier' : {'preprocesser':'tf', 'model':grid_gboost}\n",
    "}\n",
    "\n",
    "metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Builds DF of metrics for all GridSearches\n",
    "\n",
    "for grid in grid_dict.keys():\n",
    "    if grid_dict[grid]['preprocesser'] == 'cv':\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_cv)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_cv, y_test)\n",
    "        }\n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, grid_dict[grid]['model'].predict(x_test_tf)).flatten()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        balanced_acc = (specificity+recall)/2\n",
    "        metrics_dict[grid] = {\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'specificity' : specificity,\n",
    "            'balanced accuracy' : balanced_acc,\n",
    "            'accuracy' : grid_dict[grid]['model'].score(x_test_tf, y_test)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--DF of all metrics for best models\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_dict).T\n",
    "\n",
    "#with open('../data/gridsearch_metrics.data', 'wb') as fh:\n",
    "#    pickle.dump(df_metrics, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.851613</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.723975</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>-0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.583914</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>-0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.748768</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.556967</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>-0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.565574</td>\n",
       "      <td>0.742162</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.843195</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.565574</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.002305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.723982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>-0.106318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            precision    recall  specificity  \\\n",
       "LogisticRegression           0.851613  0.825000     0.622951   \n",
       "RandomForest                 0.759615  0.987500     0.180328   \n",
       "KNN                          0.748768  0.950000     0.163934   \n",
       "SVC                          0.847262  0.918750     0.565574   \n",
       "AdaBoostClassifier           0.843195  0.890625     0.565574   \n",
       "GradientBoostingClassifier   0.723982  1.000000     0.000000   \n",
       "\n",
       "                            balanced accuracy  accuracy  improvement  \n",
       "LogisticRegression                   0.723975  0.769231    -0.011269  \n",
       "RandomForest                         0.583914  0.764706    -0.002194  \n",
       "KNN                                  0.556967  0.733032    -0.009068  \n",
       "SVC                                  0.742162  0.821267     0.024867  \n",
       "AdaBoostClassifier                   0.728099  0.800905     0.002305  \n",
       "GradientBoostingClassifier           0.500000  0.723982    -0.106318  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics['improvement'] = df_metrics['accuracy'] - [.7805, .7669, .7421, .7964, .7986, .8303]\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
